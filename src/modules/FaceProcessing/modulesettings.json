{
  "Modules": {

    "FaceProcessing": {
      "Name": "Face Processing",
      "Version": "1.10.2",

      "PublishingInfo" : {
        "Description": "A number of Face image APIs including detect, recognize, and compare.",
        "Category": "Face Recognition",
        "Stack": "Python, PyTorch",
        "License": "GPL-3.0",
        "LicenseUrl": "https://opensource.org/licenses/GPL-3.0",
        "Author": "Chris Maunder, Matthew Dennis",
        "Homepage": "https://codeproject.com/ai",
        "BasedOn": "Deepstack",
        "BasedOnUrl": "https://github.com/johnolafenwa/DeepStack"
      },

      "LaunchSettings": {
        "AutoStart": true,
        "FilePath": "intelligencelayer/face.py",
        "Runtime": "python3.8",
        "RuntimeLocation": "Shared", 
        "PostStartPauseSecs": 3,        // 1 if using GPU, 0 for CPU
        "Queue": "faceprocessing_queue",// default is lower(module_id) + '_queue'
        "Parallelism": 0                // 0 = Default = number of CPUs / 2
      },

      "EnvironmentVariables": {
        "YOLOv5_AUTOINSTALL": "false",
        "YOLOv5_VERBOSE": "false",

        "PROFILE": "desktop_gpu",
        "USE_CUDA": "True",
        "MODE": "MEDIUM",

        "APPDIR": "%CURRENT_MODULE_PATH%\\intelligencelayer",
        "DATA_DIR": "%DATA_DIR%",
        "MODELS_DIR": "%CURRENT_MODULE_PATH%\\assets"
      },

      "GpuOptions" : {
        "InstallGPU": true,
        "EnableGPU": true,              // Will be coerced to false if InstallGPU = false
        "AcceleratorDeviceName": null,  // = default
        "HalfPrecision": "enable"       // 'Force', 'Enable', 'Disable': whether to force on, allow, or disable half-precision ops
      },

      "InstallOptions" : {
        "Platforms": [ "all", "!jetson" ],
        "ModuleReleases": [               // Which server version is compatible with each version of this module.
          { "ModuleVersion": "1.0",    "ServerVersionRange": [ "1.0",   "2.0.8"  ], "ReleaseDate": "2022-03-01" },
          { "ModuleVersion": "1.2",    "ServerVersionRange": [ "2.1",   "2.1.12" ], "ReleaseDate": "2023-03-20" },
          { "ModuleVersion": "1.3",    "ServerVersionRange": [ "2.1",   "2.1.12" ], "ReleaseDate": "2023-05-17" },
          { "ModuleVersion": "1.4",    "ServerVersionRange": [ "2.1",   "2.1.12" ], "ReleaseDate": "2023-08-05", "ReleaseNotes": "Bugs in error reporting corrected", "Importance": "Minor" },
          { "ModuleVersion": "1.5",    "ServerVersionRange": [ "2.1",   "2.1.12" ], "ReleaseDate": "2023-08-12", "ReleaseNotes": "PyTorch version downgrade" },
          { "ModuleVersion": "1.6",    "ServerVersionRange": [ "2.2",   "2.2.4"  ], "ReleaseDate": "2023-09-09", "ReleaseNotes": "Updated installer" },
          { "ModuleVersion": "1.7",    "ServerVersionRange": [ "2.2",   "2.2.4"  ], "ReleaseDate": "2023-09-16", "ReleaseNotes": "Updates to help Blue Iris users" },
          { "ModuleVersion": "1.8",    "ServerVersionRange": [ "2.3.0", "2.3.0"  ], "ReleaseDate": "2023-10-01", "ReleaseNotes": "Updated to match new installer SDK." },
          { "ModuleVersion": "1.8.1",  "ServerVersionRange": [ "2.3.1", "2.3.5"  ], "ReleaseDate": "2023-10-10", "ReleaseNotes": "Updated to match new installer SDK." },
          { "ModuleVersion": "1.8.2",  "ServerVersionRange": [ "2.3.5", "2.3.5"  ], "ReleaseDate": "2023-11-06", "ReleaseNotes": "Removed Raspberry Pi / Jetson support.", "Importance": "Minor" },
          { "ModuleVersion": "1.8.3",  "ServerVersionRange": [ "2.4.0", "2.4.0"  ], "ReleaseDate": "2023-12-03", "ReleaseNotes": "Installer updates, Mesh support.", "Importance": "Minor" },
          { "ModuleVersion": "1.8.4",  "ServerVersionRange": [ "2.4.1", "2.4.1"  ], "ReleaseDate": "2023-12-06", "ReleaseNotes": "Updated modulesettings schema", "Importance": "Minor" },
          { "ModuleVersion": "1.8.5",  "ServerVersionRange": [ "2.4.2", "2.4.9"  ], "ReleaseDate": "2023-12-09", "ReleaseNotes": "Installer updates", "Importance": "Minor" },
          { "ModuleVersion": "1.9.0",  "ServerVersionRange": [ "2.5.0-RC1", "2.5.0-RC5" ], "ReleaseDate": "2024-01-06", "ReleaseNotes": "Additions for dynamic explorer UI" },
          { "ModuleVersion": "1.9.1",  "ServerVersionRange": [ "2.5.0-RC1", "2.5.0-RC5" ], "ReleaseDate": "2024-01-13", "ReleaseNotes": "Changes to SDK" },
          { "ModuleVersion": "1.9.2",  "ServerVersionRange": [ "2.5.0-RC6", "" ],   "ReleaseDate": "2024-01-16", "ReleaseNotes": "Updated modulesettings schema" },
          { "ModuleVersion": "1.9.3",  "ServerVersionRange": [ "2.5.0-RC6", "" ],   "ReleaseDate": "2024-01-18", "ReleaseNotes": "Updated explorer" },
          { "ModuleVersion": "1.10.0", "ServerVersionRange": [ "2.5.0-RC6", "" ],   "ReleaseDate": "2024-01-21", "ReleaseNotes": "Module performance statistics added" },
          { "ModuleVersion": "1.10.1", "ServerVersionRange": [ "2.5.2", ""     ],   "ReleaseDate": "2024-02-08", "ReleaseNotes": "Support for CodeProject.AI Server 2.5.2" },
          { "ModuleVersion": "1.10.2", "ServerVersionRange": [ "2.5.2", ""     ],   "ReleaseDate": "2024-04-15", "ReleaseNotes": "Support for Raspberry Pi", "Importance": "Minor" }
        ]
      },

      "ModelRequirements" : [{
          "Task": "Face Detection", 
          "Architecture": "YOLOv5",
          "Format": "PyTorch"
      },
      {
          "Task": "Face Classification",
          "Architecture": "Bottleneck_IR",
          "Format": "PyTorch"
      }],

      "UIElements" : {
        "Menus": [{
          "Label": "Half Precision",
          "Options": [
            { "Label": "Force on",    "Setting": "CPAI_HALF_PRECISION", "Value": "force"   },
            { "Label": "Use Default", "Setting": "CPAI_HALF_PRECISION", "Value": "enable"  },
            { "Label": "Disable",     "Setting": "CPAI_HALF_PRECISION", "Value": "disable" }
          ]
        }]
      },

      "RouteMaps": [
        {
          "Name": "Face Detection",
          "Route": "vision/face",
          "Method": "POST",
          "Command": "detect",
          "Description": "Detects faces in an image and returns the coordinates of the faces.",
          "Inputs": [
            {
              "Name": "image",
              "Type": "File",
              "Description": "The HTTP File Object (image) to be analyzed."
            },
            {
              "Name": "min_confidence",
              "Type": "Float",
              "Description": "The minimum confidence level for an object will be detected. In the range 0.0 to 1.0.",
              "DefaultValue": 0.4,
              "MinValue": 0.0,
              "MaxValue": 1.0
            }
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            },
            {
              "Name": "message",
              "Type": "String",
              "Description": "A summary of the inference operation."
            },
            {
              "Name": "error",
              "Type": "String",
              "Description": "(Optional) An description of the error if success was false."
            },
            {
              "Name": "predictions",
              "Type": "Object",
              "Description": "An array of objects with the x_max, x_min, max, y_min, label and confidence."
            },
            {
              "Name": "inferenceMs",
              "Type": "Integer",
              "Description": "The time (ms) to perform the AI inference."
            },
            {
              "Name": "processMs",
              "Type": "Integer",
              "Description": "The time (ms) to process the image (includes inference and image manipulation operations)."
            }
          ]
        },
        {
          "Name": "Face Comparison",
          "Route": "vision/face/match",
          "Method": "POST",
          "Command": "match",
          "Description": "Compares two faces in two images and returns a value indicating how similar the faces are.",
          "Inputs": [
            {
              "Name": "image1",
              "Type": "File",
              "Description": "First HTTP File Object (image) to be analyzed."
            },
            {
              "Name": "image2",
              "Type": "File",
              "Description": "Second HTTP File Object (image) to be analyzed."
            }
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            },
            {
              "Name": "similarity",
              "Type": "Float",
              "Description": "How similar the two images are, in the range of 0.0 to 1.0."
            },
            {
              "Name": "inferenceMs",
              "Type": "Integer",
              "Description": "The time (ms) to perform the AI inference."
            },
            {
              "Name": "processMs",
              "Type": "Integer",
              "Description": "The time (ms) to process the image (includes inference and image manipulation operations)."
            }
          ]
        },
        {
          "Name": "List Registered Faces",
          "Route": "vision/face/list",
          "Method": "POST",
          "Command": "list",
          "MeshEnabled": false,
          "Description": "Lists the users that have images registered in the Face Recognition database.",
          "Inputs": [ // no inputs
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            },
            {
              "Name": "faces",
              "Type": "Object",
              "Description": "An array of the userid strings for users with registered images."
            }
          ]
        },
        {
          "Name": "Register Face",
          "Route": "vision/face/register",
          "Method": "POST",
          "Command": "register",
          "MeshEnabled": false,
          "Description": "Registers one or more images for a user for recognition. This trains the face recognition model and allows the face recognition to report back a userId based on an image you supply that may or may not contain that user's face.",
          "Inputs": [
            {
              "Name": "imageN",
              "Type": "File",
              "Description": "The one or more HTTP File Objects (images) to be registered."
            },
            {
              "Name": "userid",
              "Type": "Text",
              "Description": "The identifying string for the user."
            }
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            },
            {
              "Name": "Message",
              "Type": "Text",
              "Description": "face added"
            },
            {
              "Name": "inferenceMs",
              "Type": "Integer",
              "Description": "The time (ms) to perform the AI inference."
            },
            {
              "Name": "processMs",
              "Type": "Integer",
              "Description": "The time (ms) to process the image (includes inference and image manipulation operations)."
            }
          ]

        },
        {
          "Name": "Delete Registered Face",
          "Route": "vision/face/delete",
          "Method": "POST",
          "Command": "delete",
          "MeshEnabled": false,
          "Description": "Removes a userid and images from the Face Registration database.",
          "Inputs": [
            {
              "Name": "userid",
              "Type": "Text",
              "Description": "The identifying string for the user."
            }
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            }
          ]
        },
        {
          "Name": "Face Recognition",
          "Route": "vision/face/recognize",
          "Method": "POST",
          "Command": "recognize",
          "MeshEnabled": false,
          "Description": "Recognizes all faces in an image and returns the userId and coordinates of each face in the image. If a new (unregistered) face is detected then no userid for that face will be returned.",
          "Inputs": [
            {
              "Name": "image",
              "Type": "File",
              "Description": "The HTTP file object (image) to be analyzed."
            },
            {
              "Name": "min_confidence",
              "Type": "Float",
              "Description": "The minimum confidence level for an object will be detected. In the range 0.0 to 1.0.",
              "DefaultValue": 0.4,
              "MinValue": 0.0,
              "MaxValue": 1.0
            }
          ],
          "Outputs": [
            {
              "Name": "success",
              "Type": "Boolean",
              "Description": "True if successful."
            },
            {
              "Name": "predictions",
              "Type": "Object",
              "Description": "An array of objects with the userid, x_max, x_min, max, y_min, label and confidence."
            },
            {
              "Name": "inferenceMs",
              "Type": "Integer",
              "Description": "The time (ms) to perform the AI inference."
            },
            {
              "Name": "processMs",
              "Type": "Integer",
              "Description": "The time (ms) to process the image (includes inference and image manipulation operations)."
            }
          ]
        }
      ]
    }
  }
}